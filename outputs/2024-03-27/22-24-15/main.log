[2024-03-27 22:24:15,548][flwr][INFO] - Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)
[2024-03-27 22:24:20,024][flwr][INFO] - Flower VCE: Ray initialized with resources: {'memory': 4247371776.0, 'GPU': 1.0, 'node:127.0.0.1': 1.0, 'CPU': 12.0, 'object_store_memory': 2123685888.0}
[2024-03-27 22:24:20,026][flwr][INFO] - Initializing global parameters
[2024-03-27 22:24:20,026][flwr][INFO] - Requesting initial parameters from one random client
[2024-03-27 22:24:23,246][flwr][INFO] - Received initial parameters from one random client
[2024-03-27 22:24:23,247][flwr][INFO] - Evaluating initial parameters
[2024-03-27 22:24:38,109][flwr][INFO] - initial parameters (loss, other metrics): 1080.9185078144073, {'accuracy': 0.11153333333333333}
[2024-03-27 22:24:38,110][flwr][INFO] - FL starting
[2024-03-27 22:24:38,111][flwr][DEBUG] - fit_round 1: strategy sampled 10 clients (out of 100)
[2024-03-27 22:25:04,693][flwr][DEBUG] - fit_round 1 received 10 results and 0 failures
[2024-03-27 22:25:04,719][flwr][WARNING] - No fit_metrics_aggregation_fn provided
[2024-03-27 22:25:18,784][flwr][INFO] - fit progress: (1, 1057.2128319740295, {'accuracy': 0.34691666666666665}, 40.6725203)
[2024-03-27 22:25:18,785][flwr][DEBUG] - evaluate_round 1: strategy sampled 25 clients (out of 100)
[2024-03-27 22:26:09,448][flwr][DEBUG] - evaluate_round 1 received 25 results and 0 failures
[2024-03-27 22:26:09,450][flwr][WARNING] - No evaluate_metrics_aggregation_fn provided
[2024-03-27 22:26:09,459][flwr][DEBUG] - fit_round 2: strategy sampled 10 clients (out of 100)
[2024-03-27 22:26:28,699][flwr][DEBUG] - fit_round 2 received 10 results and 0 failures
[2024-03-27 22:26:42,781][flwr][INFO] - fit progress: (2, 892.236335515976, {'accuracy': 0.5993166666666667}, 124.6703724)
[2024-03-27 22:26:42,784][flwr][DEBUG] - evaluate_round 2: strategy sampled 25 clients (out of 100)
[2024-03-27 22:27:08,165][flwr][ERROR] - [36mray::launch_and_evaluate()[39m (pid=14812, ip=127.0.0.1)
  File "python\ray\_raylet.pyx", line 600, in ray._raylet.execute_task
  File "C:\Users\ACER\anaconda3\envs\flower_test_1\lib\site-packages\ray\_private\memory_monitor.py", line 156, in raise_if_low_memory
    raise RayOutOfMemoryError(
ray._private.memory_monitor.RayOutOfMemoryError: More than 95% of the memory on node DESKTOP-P08BMFL is used (14.95 / 15.34 GB). The top 10 memory consumers are:

PID	MEM	COMMAND
508	1.45GiB	C:\Users\ACER\anaconda3\envs\flower_test_1\python.exe d:/HocTap/flower_federated/main.py
2184	0.65GiB	C:\Program Files\Google\Chrome\Application\chrome.exe --type=renderer --no-appcompat-clear --lang=vi
16396	0.62GiB	C:\Users\ACER\anaconda3\envs\flower_test_1\python.exe C:\Users\ACER\anaconda3\envs\flower_test_1\lib
16792	0.57GiB	C:\Users\ACER\anaconda3\envs\flower_test_1\python.exe C:\Users\ACER\anaconda3\envs\flower_test_1\lib
4648	0.52GiB	C:\Users\ACER\anaconda3\envs\flower_test_1\python.exe C:\Users\ACER\anaconda3\envs\flower_test_1\lib
16100	0.52GiB	C:\Users\ACER\anaconda3\envs\flower_test_1\python.exe C:\Users\ACER\anaconda3\envs\flower_test_1\lib
16980	0.52GiB	C:\Users\ACER\anaconda3\envs\flower_test_1\python.exe C:\Users\ACER\anaconda3\envs\flower_test_1\lib
9324	0.52GiB	C:\Users\ACER\anaconda3\envs\flower_test_1\python.exe C:\Users\ACER\anaconda3\envs\flower_test_1\lib
10812	0.49GiB	C:\Users\ACER\anaconda3\envs\flower_test_1\python.exe C:\Users\ACER\anaconda3\envs\flower_test_1\lib
14812	0.49GiB	C:\Users\ACER\anaconda3\envs\flower_test_1\python.exe C:\Users\ACER\anaconda3\envs\flower_test_1\lib

In addition, up to 0.0 GiB of shared memory is currently being used by the Ray object store.
---
--- Tip: Use the `ray memory` command to list active objects in the cluster.
--- To disable OOM exceptions, set RAY_DISABLE_MEMORY_MONITOR=1.
---
[2024-03-27 22:27:31,811][flwr][DEBUG] - evaluate_round 2 received 24 results and 1 failures
[2024-03-27 22:27:31,811][flwr][DEBUG] - fit_round 3: strategy sampled 10 clients (out of 100)
[2024-03-27 22:27:52,204][flwr][DEBUG] - fit_round 3 received 10 results and 0 failures
[2024-03-27 22:28:06,253][flwr][INFO] - fit progress: (3, 355.2158710360527, {'accuracy': 0.7689333333333334}, 208.1421972)
[2024-03-27 22:28:06,254][flwr][DEBUG] - evaluate_round 3: strategy sampled 25 clients (out of 100)
[2024-03-27 22:28:53,184][flwr][DEBUG] - evaluate_round 3 received 25 results and 0 failures
[2024-03-27 22:28:53,185][flwr][DEBUG] - fit_round 4: strategy sampled 10 clients (out of 100)
[2024-03-27 22:29:11,957][flwr][DEBUG] - fit_round 4 received 10 results and 0 failures
[2024-03-27 22:29:25,891][flwr][INFO] - fit progress: (4, 275.5416248142719, {'accuracy': 0.8386833333333333}, 287.7793054)
[2024-03-27 22:29:25,891][flwr][DEBUG] - evaluate_round 4: strategy sampled 25 clients (out of 100)
[2024-03-27 22:30:11,598][flwr][DEBUG] - evaluate_round 4 received 25 results and 0 failures
[2024-03-27 22:30:11,599][flwr][DEBUG] - fit_round 5: strategy sampled 10 clients (out of 100)
[2024-03-27 22:30:30,032][flwr][DEBUG] - fit_round 5 received 10 results and 0 failures
[2024-03-27 22:30:45,346][flwr][INFO] - fit progress: (5, 220.25548389554024, {'accuracy': 0.8775666666666667}, 367.2350628)
[2024-03-27 22:30:45,347][flwr][DEBUG] - evaluate_round 5: strategy sampled 25 clients (out of 100)
[2024-03-27 22:31:34,501][flwr][DEBUG] - evaluate_round 5 received 25 results and 0 failures
[2024-03-27 22:31:34,502][flwr][INFO] - FL finished in 416.3914479
[2024-03-27 22:31:34,503][flwr][INFO] - app_fit: losses_distributed [(1, 6.765641613006592), (2, 5.700625876585643), (3, 2.322124285697937), (4, 1.8492460334300995), (5, 1.347369713783264)]
[2024-03-27 22:31:34,504][flwr][INFO] - app_fit: metrics_distributed_fit {}
[2024-03-27 22:31:34,504][flwr][INFO] - app_fit: metrics_distributed {}
[2024-03-27 22:31:34,505][flwr][INFO] - app_fit: losses_centralized [(0, 1080.9185078144073), (1, 1057.2128319740295), (2, 892.236335515976), (3, 355.2158710360527), (4, 275.5416248142719), (5, 220.25548389554024)]
[2024-03-27 22:31:34,506][flwr][INFO] - app_fit: metrics_centralized {'accuracy': [(0, 0.11153333333333333), (1, 0.34691666666666665), (2, 0.5993166666666667), (3, 0.7689333333333334), (4, 0.8386833333333333), (5, 0.8775666666666667)]}
